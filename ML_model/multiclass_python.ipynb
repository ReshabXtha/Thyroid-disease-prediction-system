{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_simplex(v, z=1):\n",
    "    \"\"\"\n",
    "    Projection onto the simplex:\n",
    "        w^* = argmin_w 0.5 ||w-v||^2 s.t. \\sum_i w_i = z, w_i >= 0\n",
    "    \"\"\"\n",
    "    # For other algorithms computing the same projection, see\n",
    "    # https://gist.github.com/mblondel/6f3b7aaad90606b98f71\n",
    "    n_features = v.shape[0]\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u) - z\n",
    "    ind = np.arange(n_features) + 1\n",
    "    cond = u - cssv / ind > 0\n",
    "    rho = ind[cond][-1]\n",
    "    theta = cssv[cond][-1] / float(rho)\n",
    "    w = np.maximum(v - theta, 0)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassSVM(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, C=1, max_iter=50, tol=0.05,\n",
    "                 random_state=None, verbose=0):\n",
    "        self.C = C\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol,\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _partial_gradient(self, X, y, i):\n",
    "        # Partial gradient for the ith sample.\n",
    "        g = np.dot(X[i], self.coef_.T) + 1\n",
    "        g[y[i]] -= 1\n",
    "        return g\n",
    "\n",
    "    def _violation(self, g, y, i):\n",
    "        # Optimality violation for the ith sample.\n",
    "        smallest = np.inf\n",
    "        for k in range(g.shape[0]):\n",
    "            if k == y[i] and self.dual_coef_[k, i] >= self.C:\n",
    "                continue\n",
    "            elif k != y[i] and self.dual_coef_[k, i] >= 0:\n",
    "                continue\n",
    "\n",
    "            smallest = min(smallest, g[k])\n",
    "\n",
    "        return g.max() - smallest\n",
    "\n",
    "    def _solve_subproblem(self, g, y, norms, i):\n",
    "        # Prepare inputs to the projection.\n",
    "        Ci = np.zeros(g.shape[0])\n",
    "        Ci[y[i]] = self.C\n",
    "        beta_hat = norms[i] * (Ci - self.dual_coef_[:, i]) + g / norms[i]\n",
    "        z = self.C * norms[i]\n",
    "        # Compute projection onto the simplex.\n",
    "        beta = projection_simplex(beta_hat, z)\n",
    "        return Ci - self.dual_coef_[:, i] - beta / norms[i]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Normalize labels.\n",
    "        self._label_encoder = LabelEncoder()\n",
    "        y = self._label_encoder.fit_transform(y)\n",
    "        # Initialize primal and dual coefficients.\n",
    "        n_classes = len(self._label_encoder.classes_)\n",
    "        self.dual_coef_ = np.zeros((n_classes, n_samples), dtype=np.float64)\n",
    "        self.coef_ = np.zeros((n_classes, n_features))\n",
    "\n",
    "        # Pre-compute norms.\n",
    "        norms = np.sqrt(np.sum(X ** 2, axis=1))\n",
    "\n",
    "        # Shuffle sample indices.\n",
    "        rs = check_random_state(self.random_state)\n",
    "        ind = np.arange(n_samples)\n",
    "        rs.shuffle(ind)\n",
    "\n",
    "        violation_init = None\n",
    "        for it in range(self.max_iter):\n",
    "            violation_sum = 0\n",
    "\n",
    "            for ii in range(n_samples):\n",
    "                i = ind[ii]\n",
    "\n",
    "                # All-zero samples can be safely ignored.\n",
    "                if norms[i] == 0:\n",
    "                    continue\n",
    "\n",
    "                g = self._partial_gradient(X, y, i)\n",
    "                v = self._violation(g, y, i)\n",
    "                violation_sum += v\n",
    "\n",
    "                if v < 1e-12:\n",
    "                    continue\n",
    "\n",
    "                # Solve subproblem for the ith sample.\n",
    "                delta = self._solve_subproblem(g, y, norms, i)\n",
    "\n",
    "                # Update primal and dual coefficients.\n",
    "                self.coef_ += (delta * X[i][:, np.newaxis]).T\n",
    "                self.dual_coef_[:, i] += delta\n",
    "\n",
    "            if it == 0:\n",
    "                violation_init = violation_sum\n",
    "\n",
    "            vratio = violation_sum / violation_init\n",
    "\n",
    "            if self.verbose >= 1:\n",
    "                print(\"iter\", it + 1, \"violation\", vratio)\n",
    "\n",
    "            if vratio < self.tol:\n",
    "                if self.verbose >= 1:\n",
    "                    print(\"Converged\")\n",
    "                break\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        decision = np.dot(X, self.coef_.T)\n",
    "        pred = decision.argmax(axis=1)\n",
    "        return self._label_encoder.inverse_transform(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
